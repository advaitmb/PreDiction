{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract</th>\n",
       "      <th>citations</th>\n",
       "      <th>pubdate</th>\n",
       "      <th>pubtype</th>\n",
       "      <th>proceedings</th>\n",
       "      <th>ccs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A meta-analysis of the impact of the inclusion and realism of human-like faces on user experiences in interfaces</td>\n",
       "      <td>['Nick Yee', 'Jeremy N Bailenson', 'Kathryn Rickertsen']</td>\n",
       "      <td>https://doi.org/10.1145/1240624.1240626</td>\n",
       "      <td>The use of embodied agents, defined as visual human-like representations accompanying a computer interface, is becoming prevalent in applications ranging from educational software to advertisements. In the current work, we assimilate previous empirical studies which compare interfaces with visually embodied agents to interfaces without agents, both using an informal, descriptive technique based on experimental results (46 studies) as well as a formal statistical meta-analysis (25 studies). Results revealed significantly larger effect sizes when analyzing subjective responses (i.e., questio...</td>\n",
       "      <td>93</td>\n",
       "      <td>April 2007</td>\n",
       "      <td>Article</td>\n",
       "      <td>CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</td>\n",
       "      <td>['Human-centered computing', 'Human computer interaction (HCI)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Session details: Faces &amp; bodies in interaction</td>\n",
       "      <td>['Anne Anderson']</td>\n",
       "      <td>https://doi.org/10.1145/3258852</td>\n",
       "      <td>No abstract available.</td>\n",
       "      <td>0</td>\n",
       "      <td>April 2007</td>\n",
       "      <td>Section</td>\n",
       "      <td>CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Improving recognition and characterization in groupware with rich embodiments</td>\n",
       "      <td>['Tadeusz Stach', 'Carl Gutwin', 'David Pinelle', 'Pourang Irani']</td>\n",
       "      <td>https://doi.org/10.1145/1240624.1240627</td>\n",
       "      <td>Embodiments are visual representations of people in a groupware system. Embodiments convey awareness information such as presence, location, and movement -- but they provide far less information than what is available from a real body in a face-to-face setting. As a result, it is often difficult to recognize and characterize other people in a groupware system without extensive communication. To address this problem, information-rich embodiments use ideas from multivariate information visualization to maximize the amount of information that is represented about a person. To investigate the ...</td>\n",
       "      <td>16</td>\n",
       "      <td>April 2007</td>\n",
       "      <td>Article</td>\n",
       "      <td>CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</td>\n",
       "      <td>['Human-centered computing', 'Collaborative and social computing', 'Collaborative and social computing theory, concepts and paradigms', 'Computer supported cooperative work', 'Social and professional topics', 'Professional topics', 'Computing and business', 'Computer supported cooperative work']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Coordinating joint activity in avatar-mediated interaction</td>\n",
       "      <td>['Robert J. Moore', 'E. Cabell Hankinson Gathman', 'Nicolas Ducheneaut', 'Eric Nickell']</td>\n",
       "      <td>https://doi.org/10.1145/1240624.1240628</td>\n",
       "      <td>Massively multiplayer online games (MMOGs) currently represent the most widely used type of social 3D virtual worlds with millions of users worldwide. Although MMOGs take face-to-face conversation as their metaphor for user-to-user interaction, avatars currently give off much less information about what users are doing than real human bodies. Consequently, users routinely encounter slippages in coordination when engaging in joint courses of action. In this study, we analyze screen-capture video of user-to-user interaction in the game, City of Heroes, under two conditions: one with the game...</td>\n",
       "      <td>24</td>\n",
       "      <td>April 2007</td>\n",
       "      <td>Article</td>\n",
       "      <td>CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</td>\n",
       "      <td>['Human-centered computing', 'Collaborative and social computing', 'Collaborative and social computing systems and tools', 'Synchronous editors', 'Information systems', 'Information systems applications', 'Collaborative and social computing systems and tools', 'Synchronous editors']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Industrial Design: Challenges and Successes Towards an integrated Product Development Process</td>\n",
       "      <td>['David Gilmore', 'Jeremy Ashley', 'Tucker Viemeister', 'Tim Wood']</td>\n",
       "      <td>https://doi.org/10.1145/1240624.2180996</td>\n",
       "      <td>No abstract available.</td>\n",
       "      <td>0</td>\n",
       "      <td>April 2007</td>\n",
       "      <td>Article</td>\n",
       "      <td>CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           1   \n",
       "2           2   \n",
       "3           3   \n",
       "4           4   \n",
       "\n",
       "                                                                                                              title  \\\n",
       "0  A meta-analysis of the impact of the inclusion and realism of human-like faces on user experiences in interfaces   \n",
       "1                                                                    Session details: Faces & bodies in interaction   \n",
       "2                                     Improving recognition and characterization in groupware with rich embodiments   \n",
       "3                                                        Coordinating joint activity in avatar-mediated interaction   \n",
       "4                     Industrial Design: Challenges and Successes Towards an integrated Product Development Process   \n",
       "\n",
       "                                                                                    authors  \\\n",
       "0                                  ['Nick Yee', 'Jeremy N Bailenson', 'Kathryn Rickertsen']   \n",
       "1                                                                         ['Anne Anderson']   \n",
       "2                        ['Tadeusz Stach', 'Carl Gutwin', 'David Pinelle', 'Pourang Irani']   \n",
       "3  ['Robert J. Moore', 'E. Cabell Hankinson Gathman', 'Nicolas Ducheneaut', 'Eric Nickell']   \n",
       "4                       ['David Gilmore', 'Jeremy Ashley', 'Tucker Viemeister', 'Tim Wood']   \n",
       "\n",
       "                                       doi  \\\n",
       "0  https://doi.org/10.1145/1240624.1240626   \n",
       "1          https://doi.org/10.1145/3258852   \n",
       "2  https://doi.org/10.1145/1240624.1240627   \n",
       "3  https://doi.org/10.1145/1240624.1240628   \n",
       "4  https://doi.org/10.1145/1240624.2180996   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  abstract  \\\n",
       "0  The use of embodied agents, defined as visual human-like representations accompanying a computer interface, is becoming prevalent in applications ranging from educational software to advertisements. In the current work, we assimilate previous empirical studies which compare interfaces with visually embodied agents to interfaces without agents, both using an informal, descriptive technique based on experimental results (46 studies) as well as a formal statistical meta-analysis (25 studies). Results revealed significantly larger effect sizes when analyzing subjective responses (i.e., questio...   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   No abstract available.   \n",
       "2  Embodiments are visual representations of people in a groupware system. Embodiments convey awareness information such as presence, location, and movement -- but they provide far less information than what is available from a real body in a face-to-face setting. As a result, it is often difficult to recognize and characterize other people in a groupware system without extensive communication. To address this problem, information-rich embodiments use ideas from multivariate information visualization to maximize the amount of information that is represented about a person. To investigate the ...   \n",
       "3  Massively multiplayer online games (MMOGs) currently represent the most widely used type of social 3D virtual worlds with millions of users worldwide. Although MMOGs take face-to-face conversation as their metaphor for user-to-user interaction, avatars currently give off much less information about what users are doing than real human bodies. Consequently, users routinely encounter slippages in coordination when engaging in joint courses of action. In this study, we analyze screen-capture video of user-to-user interaction in the game, City of Heroes, under two conditions: one with the game...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   No abstract available.   \n",
       "\n",
       "   citations     pubdate  pubtype  \\\n",
       "0         93  April 2007  Article   \n",
       "1          0  April 2007  Section   \n",
       "2         16  April 2007  Article   \n",
       "3         24  April 2007  Article   \n",
       "4          0  April 2007  Article   \n",
       "\n",
       "                                                                           proceedings  \\\n",
       "0  CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems   \n",
       "1  CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems   \n",
       "2  CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems   \n",
       "3  CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems   \n",
       "4  CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                        ccs  \n",
       "0                                                                                                                                                                                                                                          ['Human-centered computing', 'Human computer interaction (HCI)']  \n",
       "1                                                                                                                                                                                                                                                                                                        []  \n",
       "2  ['Human-centered computing', 'Collaborative and social computing', 'Collaborative and social computing theory, concepts and paradigms', 'Computer supported cooperative work', 'Social and professional topics', 'Professional topics', 'Computing and business', 'Computer supported cooperative work']  \n",
       "3               ['Human-centered computing', 'Collaborative and social computing', 'Collaborative and social computing systems and tools', 'Synchronous editors', 'Information systems', 'Information systems applications', 'Collaborative and social computing systems and tools', 'Synchronous editors']  \n",
       "4                                                                                                                                                                                                                                                                                                        []  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'papers.csv'); df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.abstract.replace('/[[\\]]/g','',regex=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract</th>\n",
       "      <th>citations</th>\n",
       "      <th>pubdate</th>\n",
       "      <th>pubtype</th>\n",
       "      <th>proceedings</th>\n",
       "      <th>ccs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A meta-analysis of the impact of the inclusion and realism of human-like faces on user experiences in interfaces</td>\n",
       "      <td>['Nick Yee', 'Jeremy N Bailenson', 'Kathryn Rickertsen']</td>\n",
       "      <td>https://doi.org/10.1145/1240624.1240626</td>\n",
       "      <td>The use of embodied agents, defined as visual human-like representations accompanying a computer interface, is becoming prevalent in applications ranging from educational software to advertisements. In the current work, we assimilate previous empirical studies which compare interfaces with visually embodied agents to interfaces without agents, both using an informal, descriptive technique based on experimental results (46 studies) as well as a formal statistical meta-analysis (25 studies). Results revealed significantly larger effect sizes when analyzing subjective responses (i.e., questio...</td>\n",
       "      <td>93</td>\n",
       "      <td>April 2007</td>\n",
       "      <td>Article</td>\n",
       "      <td>CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</td>\n",
       "      <td>['Human-centered computing', 'Human computer interaction (HCI)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Improving recognition and characterization in groupware with rich embodiments</td>\n",
       "      <td>['Tadeusz Stach', 'Carl Gutwin', 'David Pinelle', 'Pourang Irani']</td>\n",
       "      <td>https://doi.org/10.1145/1240624.1240627</td>\n",
       "      <td>Embodiments are visual representations of people in a groupware system. Embodiments convey awareness information such as presence, location, and movement -- but they provide far less information than what is available from a real body in a face-to-face setting. As a result, it is often difficult to recognize and characterize other people in a groupware system without extensive communication. To address this problem, information-rich embodiments use ideas from multivariate information visualization to maximize the amount of information that is represented about a person. To investigate the ...</td>\n",
       "      <td>16</td>\n",
       "      <td>April 2007</td>\n",
       "      <td>Article</td>\n",
       "      <td>CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</td>\n",
       "      <td>['Human-centered computing', 'Collaborative and social computing', 'Collaborative and social computing theory, concepts and paradigms', 'Computer supported cooperative work', 'Social and professional topics', 'Professional topics', 'Computing and business', 'Computer supported cooperative work']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Coordinating joint activity in avatar-mediated interaction</td>\n",
       "      <td>['Robert J. Moore', 'E. Cabell Hankinson Gathman', 'Nicolas Ducheneaut', 'Eric Nickell']</td>\n",
       "      <td>https://doi.org/10.1145/1240624.1240628</td>\n",
       "      <td>Massively multiplayer online games (MMOGs) currently represent the most widely used type of social 3D virtual worlds with millions of users worldwide. Although MMOGs take face-to-face conversation as their metaphor for user-to-user interaction, avatars currently give off much less information about what users are doing than real human bodies. Consequently, users routinely encounter slippages in coordination when engaging in joint courses of action. In this study, we analyze screen-capture video of user-to-user interaction in the game, City of Heroes, under two conditions: one with the game...</td>\n",
       "      <td>24</td>\n",
       "      <td>April 2007</td>\n",
       "      <td>Article</td>\n",
       "      <td>CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</td>\n",
       "      <td>['Human-centered computing', 'Collaborative and social computing', 'Collaborative and social computing systems and tools', 'Synchronous editors', 'Information systems', 'Information systems applications', 'Collaborative and social computing systems and tools', 'Synchronous editors']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>How it works: a field study of non-technical users interacting with an intelligent system</td>\n",
       "      <td>['Joe Tullio', 'Anind K. Dey', 'Jason Chalecki', 'James Fogarty']</td>\n",
       "      <td>https://doi.org/10.1145/1240624.1240630</td>\n",
       "      <td>In order to develop intelligent systems that attain the trust of their users, it is important to understand how users perceive such systems and develop those perceptions over time. We present an investigation into how users come to understand an intelligent system as they use it in their daily work. During a six-week field study, we interviewed eight office workers regarding the operation of a system that predicted their managers' interruptibility, comparing their mental models to the actual system model. Our results show that by the end of the study, participants were able to discount som...</td>\n",
       "      <td>61</td>\n",
       "      <td>April 2007</td>\n",
       "      <td>Article</td>\n",
       "      <td>CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</td>\n",
       "      <td>['Computing methodologies', 'Artificial intelligence', 'Human-centered computing']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>Matching attentional draw with utility in interruption</td>\n",
       "      <td>['Jennifer Gluck', 'Andrea Bunt', 'Joanna McGrenere']</td>\n",
       "      <td>https://doi.org/10.1145/1240624.1240631</td>\n",
       "      <td>This research examines a design guideline that aims to increase the positive perception of interruptions. The guideline advocates matching the amount of attention attracted by an interruption's notification method (attentional draw) to the utility of the interruption content. Our first experiment examined a set of 10 visual notification signals in terms of their detection times and established a set of three significantly different signals along the spectrum of attentional draw. Our second experiment investigated matching these different signals to interruption content with different level...</td>\n",
       "      <td>33</td>\n",
       "      <td>April 2007</td>\n",
       "      <td>Article</td>\n",
       "      <td>CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</td>\n",
       "      <td>['Human-centered computing', 'Human computer interaction (HCI)', 'HCI design and evaluation methods']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           2   \n",
       "2           3   \n",
       "3          36   \n",
       "4          37   \n",
       "\n",
       "                                                                                                              title  \\\n",
       "0  A meta-analysis of the impact of the inclusion and realism of human-like faces on user experiences in interfaces   \n",
       "1                                     Improving recognition and characterization in groupware with rich embodiments   \n",
       "2                                                        Coordinating joint activity in avatar-mediated interaction   \n",
       "3                         How it works: a field study of non-technical users interacting with an intelligent system   \n",
       "4                                                            Matching attentional draw with utility in interruption   \n",
       "\n",
       "                                                                                    authors  \\\n",
       "0                                  ['Nick Yee', 'Jeremy N Bailenson', 'Kathryn Rickertsen']   \n",
       "1                        ['Tadeusz Stach', 'Carl Gutwin', 'David Pinelle', 'Pourang Irani']   \n",
       "2  ['Robert J. Moore', 'E. Cabell Hankinson Gathman', 'Nicolas Ducheneaut', 'Eric Nickell']   \n",
       "3                         ['Joe Tullio', 'Anind K. Dey', 'Jason Chalecki', 'James Fogarty']   \n",
       "4                                     ['Jennifer Gluck', 'Andrea Bunt', 'Joanna McGrenere']   \n",
       "\n",
       "                                       doi  \\\n",
       "0  https://doi.org/10.1145/1240624.1240626   \n",
       "1  https://doi.org/10.1145/1240624.1240627   \n",
       "2  https://doi.org/10.1145/1240624.1240628   \n",
       "3  https://doi.org/10.1145/1240624.1240630   \n",
       "4  https://doi.org/10.1145/1240624.1240631   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  abstract  \\\n",
       "0  The use of embodied agents, defined as visual human-like representations accompanying a computer interface, is becoming prevalent in applications ranging from educational software to advertisements. In the current work, we assimilate previous empirical studies which compare interfaces with visually embodied agents to interfaces without agents, both using an informal, descriptive technique based on experimental results (46 studies) as well as a formal statistical meta-analysis (25 studies). Results revealed significantly larger effect sizes when analyzing subjective responses (i.e., questio...   \n",
       "1  Embodiments are visual representations of people in a groupware system. Embodiments convey awareness information such as presence, location, and movement -- but they provide far less information than what is available from a real body in a face-to-face setting. As a result, it is often difficult to recognize and characterize other people in a groupware system without extensive communication. To address this problem, information-rich embodiments use ideas from multivariate information visualization to maximize the amount of information that is represented about a person. To investigate the ...   \n",
       "2  Massively multiplayer online games (MMOGs) currently represent the most widely used type of social 3D virtual worlds with millions of users worldwide. Although MMOGs take face-to-face conversation as their metaphor for user-to-user interaction, avatars currently give off much less information about what users are doing than real human bodies. Consequently, users routinely encounter slippages in coordination when engaging in joint courses of action. In this study, we analyze screen-capture video of user-to-user interaction in the game, City of Heroes, under two conditions: one with the game...   \n",
       "3  In order to develop intelligent systems that attain the trust of their users, it is important to understand how users perceive such systems and develop those perceptions over time. We present an investigation into how users come to understand an intelligent system as they use it in their daily work. During a six-week field study, we interviewed eight office workers regarding the operation of a system that predicted their managers' interruptibility, comparing their mental models to the actual system model. Our results show that by the end of the study, participants were able to discount som...   \n",
       "4  This research examines a design guideline that aims to increase the positive perception of interruptions. The guideline advocates matching the amount of attention attracted by an interruption's notification method (attentional draw) to the utility of the interruption content. Our first experiment examined a set of 10 visual notification signals in terms of their detection times and established a set of three significantly different signals along the spectrum of attentional draw. Our second experiment investigated matching these different signals to interruption content with different level...   \n",
       "\n",
       "   citations     pubdate  pubtype  \\\n",
       "0         93  April 2007  Article   \n",
       "1         16  April 2007  Article   \n",
       "2         24  April 2007  Article   \n",
       "3         61  April 2007  Article   \n",
       "4         33  April 2007  Article   \n",
       "\n",
       "                                                                           proceedings  \\\n",
       "0  CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems   \n",
       "1  CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems   \n",
       "2  CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems   \n",
       "3  CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems   \n",
       "4  CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                        ccs  \n",
       "0                                                                                                                                                                                                                                          ['Human-centered computing', 'Human computer interaction (HCI)']  \n",
       "1  ['Human-centered computing', 'Collaborative and social computing', 'Collaborative and social computing theory, concepts and paradigms', 'Computer supported cooperative work', 'Social and professional topics', 'Professional topics', 'Computing and business', 'Computer supported cooperative work']  \n",
       "2               ['Human-centered computing', 'Collaborative and social computing', 'Collaborative and social computing systems and tools', 'Synchronous editors', 'Information systems', 'Information systems applications', 'Collaborative and social computing systems and tools', 'Synchronous editors']  \n",
       "3                                                                                                                                                                                                                        ['Computing methodologies', 'Artificial intelligence', 'Human-centered computing']  \n",
       "4                                                                                                                                                                                                     ['Human-centered computing', 'Human computer interaction (HCI)', 'HCI design and evaluation methods']  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.abstract != \"No abstract available.\"].reset_index(drop=True); df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/fastai2/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "data_lm = TextDataLoaders.from_df(df, path, valid_pct=0.1, seed=7, text_col='abstract', is_lm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm = language_model_learner(data_lm, AWD_LSTM, metrics=[accuracy, Perplexity()], path=path, wd=0.1, drop_mult=0.2).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.017378008365631102, lr_steep=6.309573450380412e-07)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.fit_one_cycle??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.258344</td>\n",
       "      <td>4.022088</td>\n",
       "      <td>0.303494</td>\n",
       "      <td>55.817509</td>\n",
       "      <td>02:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.model_dir = '../models/design'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('../data/../models/design/1epoch.pth')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_lm.save('1epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'What do you think about outliers often go everywhere . We examine how users strive to observed data within objects . However'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_lm.predict(\"What do you think\", n_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.text.learner.LMLearner at 0x7fec9fa12a00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_lm.load('4epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.863764</td>\n",
       "      <td>3.944371</td>\n",
       "      <td>0.312952</td>\n",
       "      <td>51.643818</td>\n",
       "      <td>03:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.651252</td>\n",
       "      <td>3.843732</td>\n",
       "      <td>0.323296</td>\n",
       "      <td>46.699417</td>\n",
       "      <td>03:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.306215</td>\n",
       "      <td>3.858548</td>\n",
       "      <td>0.322826</td>\n",
       "      <td>47.396488</td>\n",
       "      <td>03:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm.fit_one_cycle(3, 2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('../data/../models/design/1epoch.pth')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_lm.save('1epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The cube is a novel medium that can be combined with an interactive table that enables users to view the data and'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_lm.predict('The cube', n_words=20, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_lm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b92a0b3fac9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn_lm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage_model_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAWD_LSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPerplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_lm' is not defined"
     ]
    }
   ],
   "source": [
    "learn_lm = language_model_learner(data_lm, AWD_LSTM, metrics=[accuracy, Perplexity()], path=path, wd=0.2, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.017378008365631102, lr_steep=0.015848932787775993)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.304290</td>\n",
       "      <td>4.050635</td>\n",
       "      <td>0.304398</td>\n",
       "      <td>57.433907</td>\n",
       "      <td>01:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.945845</td>\n",
       "      <td>3.973041</td>\n",
       "      <td>0.310312</td>\n",
       "      <td>53.145916</td>\n",
       "      <td>02:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.759657</td>\n",
       "      <td>3.864102</td>\n",
       "      <td>0.321587</td>\n",
       "      <td>47.660461</td>\n",
       "      <td>02:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.471125</td>\n",
       "      <td>3.854045</td>\n",
       "      <td>0.323848</td>\n",
       "      <td>47.183533</td>\n",
       "      <td>02:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm.unfreeze()\n",
    "learn_lm.fit_one_cycle(3, 2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Recent user studies and'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_lm.predict('Recent user studies', n_words=1, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learn_lm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c092e454eb51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/advaitmb/notebooks/projects/PreDiction/models/design/4epochslearner.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'learn_lm' is not defined"
     ]
    }
   ],
   "source": [
    "learn_lm.export('/home/advaitmb/notebooks/projects/PreDiction/models/design/4epochslearner.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner('/home/advaitmb/notebooks/projects/PreDiction/models/design/4epochslearner.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_hum = load_learner('/home/advaitmb/notebooks/projects/PreDiction/models/5epochslearner_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.text.learner.LMLearner at 0x7f416112eac0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(12304, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(12304, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=12304, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(learn, text:str, n_words:int, no_unk:bool=True, top_k:int=10, beam_sz:int=1000, temperature:float=1.,\n",
    "                    sep:str=' ', decoder=decode_spec_tokens):\n",
    "    learn.model.reset()\n",
    "    learn.model.eval()\n",
    "    idx = learn.dls.test_dl([text]).items[0][None]\n",
    "    nodes = None\n",
    "    nodes = idx.clone()\n",
    "    scores = idx.new_zeros(1).float()\n",
    "    if no_unk: unk_idx = learn.dls.vocab.index(UNK)\n",
    "    with torch.no_grad():\n",
    "        for k in progress_bar(range(n_words), leave=False):\n",
    "            out = F.log_softmax(learn.model(idx)[0][:,-1], dim=-1)\n",
    "            if no_unk: out[:, unk_idx] = -float('Inf')\n",
    "            values, indices = out.topk(top_k, dim=-1)\n",
    "            scores = (-values + scores[:,None]).view(-1)\n",
    "            indices_idx = torch.arange(0,nodes.size(0))[:,None].expand(nodes.size(0), top_k).contiguous().view(-1)\n",
    "            sort_idx = scores.argsort()[:beam_sz]\n",
    "            scores = scores[sort_idx]\n",
    "            nodes = torch.cat([nodes[:,None].expand(nodes.size(0),top_k,nodes.size(1)),\n",
    "                                    indices[:,:,None].expand(nodes.size(0),top_k,1),], dim=2)\n",
    "            nodes = nodes.view(-1, nodes.size(2))[sort_idx]\n",
    "            learn.hidden = [(h[0][:,indices_idx[sort_idx],:],h[1][:,indices_idx[sort_idx],:]) for h in learn.model[0].hidden]\n",
    "            idx = nodes[:,-1][:,None]\n",
    "        if temperature != 1.: scores.div_(temperature)\n",
    "        node_idx = torch.multinomial(torch.exp(-scores), 1).item()\n",
    "        num = learn.dls.train_ds.numericalize\n",
    "        tokens = [num.vocab[i] for i in nodes[node_idx][1:] if num.vocab[i] not in [BOS, PAD]]\n",
    "        sep = learn.dls.train_ds.tokenizer.sep\n",
    "        return sep.join(decoder(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'We propose'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('We propose to the most beautiful man on the earth …',\n",
       " '/n',\n",
       " 'We propose a new approach to interactive visual feedback for visually impaired')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_hum.predict(text = text , n_words = 10, temperature = 0.7),'/n', learn.predict(text = text , n_words = 10, temperature = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai2",
   "language": "python",
   "name": "fastai2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
